# 自定义服务商

如果你用的 AI 服务不在 MoryFlow 的预设列表里，可以自己添加。

## 什么时候用

- 用兼容 OpenAI 协议的第三方服务
- 连接公司内部的 AI 服务
- 用其他聚合平台
- 试用新的 AI 服务

## OpenAI 兼容协议

大多数 AI 服务都兼容 OpenAI 的 API 协议，也就是说只要知道：

1. **API 端点**（Base URL）
2. **API Key**
3. **模型名称**

就能在 MoryFlow 里用。

## 添加服务商

### 怎么添加

1. 打开设置 → 模型管理
2. 滚到「自定义服务商」
3. 点「添加服务商」

<!-- 截图占位符：添加自定义服务商 -->
![添加自定义服务商](/images/settings/add-provider.png)

### 要填什么

| 配置项 | 说明 | 示例 |
|--------|------|------|
| **名称** | 显示名称 | My AI Service |
| **Base URL** | API 端点地址 | `https://api.example.com/v1` |
| **API Key** | 认证密钥 | `sk-xxxxx` |
| **模型列表** | 可用的模型 | `gpt-4, gpt-3.5-turbo` |

## 常见服务商配置

### Azure OpenAI

```
Base URL: https://{your-resource}.openai.azure.com/openai/deployments/{deployment-name}
API Key: 你的 Azure API Key
```

### Groq

```
Base URL: https://api.groq.com/openai/v1
API Key: 你的 Groq API Key
模型: llama-3.1-70b-versatile, mixtral-8x7b-32768
```

### Together AI

```
Base URL: https://api.together.xyz/v1
API Key: 你的 Together API Key
模型: meta-llama/Llama-3-70b-chat-hf
```

### Perplexity

```
Base URL: https://api.perplexity.ai
API Key: 你的 Perplexity API Key
模型: llama-3.1-sonar-large-128k-online
```

### 本地 LM Studio

```
Base URL: http://localhost:1234/v1
API Key: 留空或随便填
模型: 在 LM Studio 里加载的模型名
```

### 本地 vLLM

```
Base URL: http://localhost:8000/v1
API Key: 留空
模型: 你部署的模型名
```

## 添加自定义模型

配置好服务商后，还要添加可用的模型：

1. 在服务商配置里点「添加模型」
2. 填模型信息：
   - **模型 ID**：API 调用时用的名字
   - **显示名称**：界面上显示的名字
   - **上下文窗口**：模型支持的最大 token 数
   - **能力标签**：标记模型支持什么功能

<!-- 截图占位符：添加自定义模型 -->
![添加自定义模型](/images/settings/add-custom-model.png)

## 测试一下

配置完建议测试一下：

1. 在聊天面板选新加的模型
2. 发条简单消息
3. 看看能不能正常回复

## 出问题了

### 连接失败

1. 检查 Base URL 对不对（一般以 `/v1` 结尾）
2. 确认 API Key 有效
3. 检查网络能不能访问这个服务

### 模型用不了

1. 确认模型 ID 拼写对了
2. 确认这个模型在你账户里可用
3. 检查服务商有没有地区限制

### 响应格式不对

有些服务商可能不完全兼容 OpenAI 协议，可能需要：
- 看看服务商的文档
- 调整请求参数
- 联系服务商

## 安全提醒

- API Key 存在本地，不会上传
- 用自建服务时，确保通信加密（HTTPS）
- 定期换一下 API Key
